{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import json\n",
    "import csv\n",
    "import time\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getPushshiftData(after, before):\n",
    "    sub = \"india\"\n",
    "    url = 'https://api.pushshift.io/reddit/search/submission/?size=1000&after='+str(after)+'&before='+str(before)+'&subreddit='+str(sub)\n",
    "    print(url)\n",
    "    r = requests.get(url)\n",
    "    data = json.loads(r.text)\n",
    "    return data['data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collectSubData(subm):\n",
    "    subData = list() #list to store data points\n",
    "    sub_id = subm['id']\n",
    "    title = subm['title']  \n",
    "    \n",
    "    try:\n",
    "        body = subm['selftext']\n",
    "    except KeyError:\n",
    "        body = \"\" \n",
    "    \n",
    "    try:\n",
    "        flair = subm['link_flair_text']\n",
    "    except KeyError:\n",
    "        flair = \"NaN\" \n",
    "    \n",
    "    numComms = subm['num_comments']\n",
    "    created = datetime.datetime.fromtimestamp(subm['created_utc']) # time\n",
    "    score = subm['score']\n",
    "    over_age = subm['over_18']\n",
    "    author = subm['author']\n",
    "\n",
    "    subData.append((title,body,flair,numComms,created,score,over_age,author))\n",
    "    subStats[sub_id] = subData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#before and after dates\n",
    "before = \"1533081600\" #August 1st 2018\n",
    "after = \"1527811200\"  #June 1st 2018\n",
    "subCount = 0\n",
    "subStats = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://api.pushshift.io/reddit/search/submission/?size=1000&after=1527811200&before=1533081600&subreddit=india\n",
      "1000\n",
      "2018-06-03 12:08:33\n",
      "https://api.pushshift.io/reddit/search/submission/?size=1000&after=1528007913&before=1533081600&subreddit=india\n",
      "1000\n",
      "2018-06-05 14:26:01\n",
      "https://api.pushshift.io/reddit/search/submission/?size=1000&after=1528188961&before=1533081600&subreddit=india\n",
      "1000\n",
      "2018-06-07 14:37:22\n",
      "https://api.pushshift.io/reddit/search/submission/?size=1000&after=1528362442&before=1533081600&subreddit=india\n",
      "1000\n",
      "2018-06-09 15:23:05\n",
      "https://api.pushshift.io/reddit/search/submission/?size=1000&after=1528537985&before=1533081600&subreddit=india\n",
      "1000\n",
      "2018-06-11 18:55:28\n",
      "https://api.pushshift.io/reddit/search/submission/?size=1000&after=1528723528&before=1533081600&subreddit=india\n",
      "1000\n",
      "2018-06-13 22:15:33\n",
      "https://api.pushshift.io/reddit/search/submission/?size=1000&after=1528908333&before=1533081600&subreddit=india\n",
      "1000\n",
      "2018-06-16 09:47:30\n",
      "https://api.pushshift.io/reddit/search/submission/?size=1000&after=1529122650&before=1533081600&subreddit=india\n",
      "1000\n",
      "2018-06-18 18:39:48\n",
      "https://api.pushshift.io/reddit/search/submission/?size=1000&after=1529327388&before=1533081600&subreddit=india\n",
      "1000\n",
      "2018-06-20 22:20:16\n",
      "https://api.pushshift.io/reddit/search/submission/?size=1000&after=1529513416&before=1533081600&subreddit=india\n",
      "1000\n",
      "2018-06-23 02:42:59\n",
      "https://api.pushshift.io/reddit/search/submission/?size=1000&after=1529701979&before=1533081600&subreddit=india\n",
      "1000\n",
      "2018-06-25 16:24:33\n",
      "https://api.pushshift.io/reddit/search/submission/?size=1000&after=1529924073&before=1533081600&subreddit=india\n",
      "1000\n",
      "2018-06-27 16:12:58\n",
      "https://api.pushshift.io/reddit/search/submission/?size=1000&after=1530096178&before=1533081600&subreddit=india\n",
      "1000\n",
      "2018-06-29 16:03:59\n",
      "https://api.pushshift.io/reddit/search/submission/?size=1000&after=1530268439&before=1533081600&subreddit=india\n",
      "1000\n",
      "2018-07-02 00:53:31\n",
      "https://api.pushshift.io/reddit/search/submission/?size=1000&after=1530473011&before=1533081600&subreddit=india\n",
      "1000\n",
      "2018-07-04 10:44:41\n",
      "https://api.pushshift.io/reddit/search/submission/?size=1000&after=1530681281&before=1533081600&subreddit=india\n",
      "1000\n",
      "2018-07-06 09:41:39\n",
      "https://api.pushshift.io/reddit/search/submission/?size=1000&after=1530850299&before=1533081600&subreddit=india\n",
      "1000\n",
      "2018-07-08 14:46:34\n",
      "https://api.pushshift.io/reddit/search/submission/?size=1000&after=1531041394&before=1533081600&subreddit=india\n",
      "1000\n",
      "2018-07-10 14:37:13\n",
      "https://api.pushshift.io/reddit/search/submission/?size=1000&after=1531213633&before=1533081600&subreddit=india\n",
      "1000\n",
      "2018-07-12 11:48:27\n",
      "https://api.pushshift.io/reddit/search/submission/?size=1000&after=1531376307&before=1533081600&subreddit=india\n",
      "1000\n",
      "2018-07-14 12:29:29\n",
      "https://api.pushshift.io/reddit/search/submission/?size=1000&after=1531551569&before=1533081600&subreddit=india\n",
      "1000\n",
      "2018-07-16 18:13:54\n",
      "https://api.pushshift.io/reddit/search/submission/?size=1000&after=1531745034&before=1533081600&subreddit=india\n",
      "1000\n",
      "2018-07-18 16:41:26\n",
      "https://api.pushshift.io/reddit/search/submission/?size=1000&after=1531912286&before=1533081600&subreddit=india\n",
      "1000\n",
      "2018-07-20 15:02:05\n",
      "https://api.pushshift.io/reddit/search/submission/?size=1000&after=1532079125&before=1533081600&subreddit=india\n",
      "1000\n",
      "2018-07-22 14:07:51\n",
      "https://api.pushshift.io/reddit/search/submission/?size=1000&after=1532248671&before=1533081600&subreddit=india\n",
      "1000\n",
      "2018-07-24 12:44:17\n",
      "https://api.pushshift.io/reddit/search/submission/?size=1000&after=1532416457&before=1533081600&subreddit=india\n",
      "1000\n",
      "2018-07-26 13:56:22\n",
      "https://api.pushshift.io/reddit/search/submission/?size=1000&after=1532593582&before=1533081600&subreddit=india\n",
      "1000\n",
      "2018-07-28 15:14:38\n",
      "https://api.pushshift.io/reddit/search/submission/?size=1000&after=1532771078&before=1533081600&subreddit=india\n",
      "1000\n",
      "2018-07-30 20:00:58\n",
      "https://api.pushshift.io/reddit/search/submission/?size=1000&after=1532961058&before=1533081600&subreddit=india\n",
      "676\n",
      "2018-08-01 05:16:31\n",
      "https://api.pushshift.io/reddit/search/submission/?size=1000&after=1533080791&before=1533081600&subreddit=india\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "data = getPushshiftData(after, before)\n",
    "\n",
    "# Will run until all posts have been gathered \n",
    "# from the 'after' date up until before date\n",
    "while len(data) > 0:\n",
    "    for submission in data:\n",
    "        collectSubData(submission)\n",
    "        subCount+=1\n",
    "    # Calls getPushshiftData() with the created date of the last submission\n",
    "    print(len(data))\n",
    "    print(str(datetime.datetime.fromtimestamp(data[-1]['created_utc'])))\n",
    "    after = data[-1]['created_utc']\n",
    "    data = getPushshiftData(after, before)\n",
    "    \n",
    "print(len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28676 submissions have added to list\n",
      "1st entry is:\n",
      "Brahmins who eat nonveg created: 2018-06-01 05:32:19\n",
      "Last entry is:\n",
      "Are there any or am I alone? created: 2018-08-01 05:16:31\n"
     ]
    }
   ],
   "source": [
    "# to ensure that list has been created\n",
    "\n",
    "print(str(len(subStats)) + \" submissions have added to list\")\n",
    "print(\"1st entry is:\")\n",
    "print(list(subStats.values())[-9][0][0] + \" created: \" + str(list(subStats.values())[0][0][4]))\n",
    "print(\"Last entry is:\")\n",
    "print(list(subStats.values())[-9][0][1] + \" created: \" + str(list(subStats.values())[-1][0][4]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28676 submissions have been uploaded\n"
     ]
    }
   ],
   "source": [
    "def updateSubs_file():\n",
    "    upload_count = 0\n",
    "    file = \"extracted_data.csv\"\n",
    "    with open(file, 'w', newline='', encoding='utf-8') as file: \n",
    "        a = csv.writer(file, delimiter=',')\n",
    "        headers = [\"TITLE\",\"BODY\",\"FLAIR\",\"NO_OF_COMMENTS\",\"TIMESTAMP\",\"UPVOTES\",\"OVER_AGE\",\"AUTHOR\"]\n",
    "        a.writerow(headers)\n",
    "        for sub in subStats:\n",
    "            a.writerow(subStats[sub][0])\n",
    "            upload_count+=1\n",
    "            \n",
    "        print(str(upload_count) + \" submissions have been uploaded\")\n",
    "\n",
    "updateSubs_file()\n",
    "\n",
    "subStats = list(subStats.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('No takers for Air India - Zero Bids', '', 'NaN', 1, datetime.datetime(2018, 6, 1, 5, 36, 29), 11, False, 'sam_k5')]\n",
      "NaN\n",
      "[('Just Another Immigrant (2018) | Official Trailer | SHOWTIME Documentary Series', '', 'Non-Political', 1, datetime.datetime(2018, 6, 1, 5, 48, 25), 0, False, 'RedditShmedit')]\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "extracted_dict = {\n",
    "    \"TITLE\":[], \n",
    "    \"BODY\":[], \n",
    "    \"FLAIR\":[], \n",
    "    \"NO_OF_COMMENTS\":[], \n",
    "    \"TIMESTAMP\":[], \n",
    "    \"UPVOTES\":[], \n",
    "    \"OVER_AGE\":[], \n",
    "    \"AUTHOR\":[]\n",
    "}\n",
    "\n",
    "for sub in subStats:\n",
    "    extracted_dict[\"TITLE\"].append(sub[0][0])\n",
    "    extracted_dict[\"BODY\"].append(sub[0][1])\n",
    "    extracted_dict[\"FLAIR\"].append(sub[0][2])\n",
    "    extracted_dict[\"NO_OF_COMMENTS\"].append(sub[0][3])\n",
    "    extracted_dict[\"TIMESTAMP\"].append(sub[0][4])\n",
    "    extracted_dict[\"UPVOTES\"].append(sub[0][5])\n",
    "    extracted_dict[\"OVER_AGE\"].append(sub[0][6])\n",
    "    extracted_dict[\"AUTHOR\"].append(sub[0][7])\n",
    "\n",
    "pandas_data = pd.DataFrame(extracted_dict)\n",
    "#print(pandas_data)\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
